{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff9a534c",
   "metadata": {},
   "source": [
    "### Imports and load .env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1312a30c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MongoDB connected (.env loaded from c:\\Users\\User\\Desktop\\MyParliament\\MyParliament\\3_app_system\\backend\\.env)\n"
     ]
    }
   ],
   "source": [
    "import pymongo\n",
    "import json\n",
    "import re\n",
    "import random\n",
    "import os\n",
    "from datetime import datetime\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import threading\n",
    "from dotenv import load_dotenv\n",
    "from pathlib import Path\n",
    "from fuzzywuzzy import process\n",
    "\n",
    "project_root = Path.cwd().parents[1]\n",
    "backend_env_path = project_root / \"3_app_system\" / \"backend\" / \".env\"\n",
    "\n",
    "if not backend_env_path.exists():\n",
    "    raise FileNotFoundError(f\".env not found at {backend_env_path}\")\n",
    "\n",
    "load_dotenv(backend_env_path)\n",
    "\n",
    "MONGO_URI = os.getenv(\"MONGO_URI\")\n",
    "if not MONGO_URI:\n",
    "    raise ValueError(\"MONGO_URI not found in .env\")\n",
    "\n",
    "client = pymongo.MongoClient(MONGO_URI)\n",
    "db = client[\"MyParliament\"]\n",
    "\n",
    "hansard_col = db[\"hansard_core500\"]\n",
    "honorific_col = db[\"honorific_dictionary\"]\n",
    "segmented_col = db[\"hansard_segmented500\"]\n",
    "mp_col = db[\"MP\"]\n",
    "\n",
    "mp_names = [mp[\"full_name_with_titles\"] for mp in mp_col.find({}, {\"full_name_with_titles\": 1})]\n",
    "\n",
    "thread_local = threading.local()\n",
    "def get_db_connection():\n",
    "    if not hasattr(thread_local, \"client\"):\n",
    "        thread_local.client = pymongo.MongoClient(MONGO_URI)\n",
    "    return thread_local.client[\"MyParliament\"]\n",
    "\n",
    "print(f\"MongoDB connected (.env loaded from {backend_env_path})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f014d90",
   "metadata": {},
   "source": [
    "### Load honorific_dictionary and analysis JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "24a42795",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dynamic honorific regex built: 24 terms\n"
     ]
    }
   ],
   "source": [
    "honorific_doc = honorific_col.find_one({\"version\": \"2.0\"})\n",
    "if not honorific_doc:\n",
    "    raise ValueError(\"honorific_dictionary version 2.0 not found\")\n",
    "\n",
    "all_honorifics = set()\n",
    "for category in honorific_doc[\"categories\"].values():\n",
    "    all_honorifics.update([h.strip().rstrip(\"'\") for h in category])\n",
    "\n",
    "all_honorifics.update([\"Yang Berhormat\", \"Timbalan Yang di-Pertua\", \"Enche'\", \"Mr.\"])\n",
    "\n",
    "honorific_regex = \"|\".join(sorted(all_honorifics, key=len, reverse=True))\n",
    "print(f\"Dynamic honorific regex built: {len(all_honorifics)} terms\")\n",
    "\n",
    "with open(\"../03_patternAnalysis/combined_parliament_analysis.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    analysis_data = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aa5646e",
   "metadata": {},
   "source": [
    "### Regex patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a3947cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "PRIMARY_PATTERN = re.compile(\n",
    "    rf\"^({honorific_regex})\\s+([A-Za-z'\\s]+?)\\s*(\\[([A-Za-z\\s\\-]+)\\])?:?\\s*\",\n",
    "    re.IGNORECASE\n",
    ")\n",
    "FALLBACK_PATTERN = re.compile(r\"^([A-Z][A-Za-z'\\s]+?)\\s*(\\[.*?\\])?:?\\s*\", re.IGNORECASE)\n",
    "ENGLISH_OLD_PATTERN = re.compile(r\"^(Mr\\.|Encik|Tuan|Enche')\\s+([A-Za-z\\s]+?):\", re.IGNORECASE)\n",
    "\n",
    "def get_decade(year: int) -> str:\n",
    "    return \"pre1970\" if year < 1970 else \"post1970\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c70474d3",
   "metadata": {},
   "source": [
    "### Helper function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9683c90f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_line(line):\n",
    "    line = re.sub(r'\\s+', ' ', line.strip())\n",
    "    if not line or re.match(r'^[\\d\\W]+$', line):  # Only skip empty or pure symbols/numbers\n",
    "        return None\n",
    "    return line\n",
    "\n",
    "def skip_header_and_doa(lines, max_lines=300):\n",
    "    start_idx = 0\n",
    "    in_attendance = False\n",
    "    attendance_keywords = [\"KEHADIRAN AHLI-AHLI\", \"AHLI-AHLI YANG HADIR\", \"KEHADIRAN\"]\n",
    "    for i, line in enumerate(lines[:max_lines]):\n",
    "        stripped = line.strip().upper()\n",
    "        if any(kw in stripped for kw in attendance_keywords + [\"NASKHAH BELUM DISEM\", \"DEWAN RAKYAT\", \"PENGGAL\", \"MESYUARAT\", \"KANDUNGAN\", \"WAKTU PERTANYAAN\", \"BIL.\"]):\n",
    "            start_idx = i + 1\n",
    "            if any(kw in stripped for kw in attendance_keywords):\n",
    "                in_attendance = True\n",
    "        if \"DOA\" in stripped and len(stripped.split()) < 10:  # Short DOA line\n",
    "            start_idx = max(start_idx, i + 1)\n",
    "        # Exit attendance mode when real speech starts\n",
    "        if in_attendance and (\":\" in stripped and any(h in stripped.upper() for h in all_honorifics)):\n",
    "            in_attendance = False\n",
    "            start_idx = i\n",
    "    return start_idx\n",
    "\n",
    "def extract_speaker(line, decade):\n",
    "    if not ':' in line:  # Must have colon for speaker tag\n",
    "        return None, None\n",
    "    \n",
    "    if decade == \"pre1970\":\n",
    "        m = ENGLISH_OLD_PATTERN.match(line)\n",
    "        if m:\n",
    "            candidate = m.group(1) + \" \" + m.group(2).strip()\n",
    "            best_match, score = process.extractOne(candidate, mp_names)\n",
    "            if score > 85:\n",
    "                return best_match, None\n",
    "    \n",
    "    m = PRIMARY_PATTERN.match(line)\n",
    "    if m:\n",
    "        honorific = m.group(1).strip()\n",
    "        name = m.group(2).strip()\n",
    "        candidate = f\"{honorific} {name}\"\n",
    "        best_match, score = process.extractOne(candidate, mp_names)\n",
    "        if score > 85:\n",
    "            constituency = m.group(4) if m.group(4) else None\n",
    "            return best_match, constituency\n",
    "    \n",
    "    m = FALLBACK_PATTERN.match(line)\n",
    "    if m:\n",
    "        candidate = m.group(1).strip()\n",
    "        best_match, score = process.extractOne(candidate, mp_names)\n",
    "        if score > 85:\n",
    "            return best_match, m.group(2)[1:-1] if m.group(2) else None\n",
    "    return None, None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "659d48d4",
   "metadata": {},
   "source": [
    "### Core segmentation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d61b6b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_document(doc_id, text, year):\n",
    "    lines = [clean_line(l) for l in text.splitlines() if clean_line(l)]\n",
    "    decade = get_decade(year)\n",
    "    start_idx = skip_header_and_doa(lines)\n",
    "    \n",
    "    segments = []\n",
    "    current_speaker = None\n",
    "    current_constituency = None\n",
    "    current_text = []\n",
    "    current_start_line = start_idx\n",
    "    \n",
    "    for i, line in enumerate(lines[start_idx:], start=start_idx):\n",
    "        speaker, constituency = extract_speaker(line, decade)\n",
    "        if speaker:\n",
    "            if current_speaker and current_text:\n",
    "                segments.append({\n",
    "                    \"speaker\": current_speaker,\n",
    "                    \"constituency\": current_constituency,\n",
    "                    \"start_line\": current_start_line,\n",
    "                    \"text\": \" \".join(current_text).strip()\n",
    "                })\n",
    "            current_speaker = speaker\n",
    "            current_constituency = constituency\n",
    "            # Pure speech content after colon\n",
    "            content = line.split(':', 1)[1].strip() if ':' in line else line\n",
    "            current_text = [content] if content else []\n",
    "            current_start_line = i\n",
    "        elif current_speaker:\n",
    "            current_text.append(line)\n",
    "    \n",
    "    if current_speaker and current_text:\n",
    "        segments.append({\n",
    "            \"speaker\": current_speaker,\n",
    "            \"constituency\": current_constituency,\n",
    "            \"start_line\": current_start_line,\n",
    "            \"text\": \" \".join(current_text).strip()\n",
    "        })\n",
    "    \n",
    "    return {\n",
    "        \"document_id\": str(doc_id),\n",
    "        \"hansardDate\": year,\n",
    "        \"decade\": decade,\n",
    "        \"segment_count\": len(segments),\n",
    "        \"segments\": segments\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c648a12e",
   "metadata": {},
   "source": [
    "### Test 10 random samples + QA/Injection insight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb9f3c1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== TESTING 10 RANDOM SAMPLES ===\n",
      "\n",
      "Sample 1 | ID: 673390ead052c3fbabd83b44 | Date: 2000-03-30 | Decade: post1970 | Segments: 273\n",
      "   First speaker: Tuan Ong Tin Kim [None]\n",
      "   First text: Tuan Yang di-Pertua, peruntukan untuk menubuhkan Bursa Buruh Elektronik (ELX) ini adalah sebanyak RM28.26 juta. Kerajaan sedang dalam proses peringkat...\n",
      "   QA Example:\n",
      "     Q (YB Tuan Haji Abdul Latiff bin Abdul Rahman): Terima kasih Tuan Yang di Pertua, soalan tambahan. Saya ingin mengucap tahniah di atas usaha-usaha k...\n",
      "     Q (Dr V. David): Tuan Yang di-Pertua, terima kasih Yang Berhormat bagi Sungai Benut. Sepatutnya soalan tambahan ini s...\n",
      "     Q (YB Tuan Lim Lip Eng): Tuan Yang di-Pertua, terima kasih. Soalan tambahan saya adalah jikalau peguam asing akan dibenarkan ...\n",
      "     Q (YB Tuan Haji Abdul Latiff bin Abdul Rahman): Tuan Yang di-Pertua, terima kasih. Soalan mengenai ada sekatan di antara peguam Semenanjung dengan p...\n",
      "\n",
      "Sample 2 | ID: 67338d77d052c3fbabd83b09 | Date: 1999-04-19 | Decade: post1970 | Segments: 252\n",
      "   First speaker: Tuan Mark Koding [None]\n",
      "   First text: CAWANGAN DOKUMENTASI PARLIMEN MALAYSIA 1999 DR.19.4.1999 AHLI-AHLI DEWA N RAKYAT Yang Berhonnat Tuan Yang di-Pertua, Tun Mohamed Zahir bin Haji Ismail...\n",
      "   QA Example:\n",
      "     Q (Dr V. David): Tuan Yang di-Pertua, soalan tambahan. Dalam jawapan Yang Berhonnat Timbalan Menteri menyentuh tentan...\n",
      "     Q (Dr V. David): Tuan Yang di-Pertua, bolehkah Yang Berhormat Timbalan Menteri memberitahu saya setakat manakah pemaj...\n",
      "     Q (Datuk Peter Lo Su Yin): Minta maaf, Yang Berhormat. Saya tidak dapat tangkap soalan itu....\n",
      "     Q (Dr V. David): Bolehkah Yang Berhonnat Timbalan Menteri memberitahu saya, setakat manakah pemaju-pemaju mengikut ar...\n",
      "   Injection Example:\n",
      "     Injection in Tuan Mark Koding's speech: mentions Tuan Abdul\n",
      "     Injection in Tuan Mark Koding's speech: mentions Dr. Patau Rubis\n",
      "\n",
      "Sample 3 | ID: 67325d3952c74147fa57323a | Date: 1963-08-15 | Decade: pre1970 | Segments: 42\n",
      "   First speaker: Tuan Abdul [None]\n",
      "   First text: 956 The Honourable ENCHE' AHMAD BOESTAMAM (Setapak). ENCHE KHONG KOK YAT (Batu Gajah). \" ENCHE' MOHAMED DAHARI BIN HAJI MOHD. ALI (Kuala Selangor). NI...\n",
      "   QA Example:\n",
      "     Q (Tuan D.R Seenivasagam): Mr Speaker, Sir, the Honourable the Deputy Prime Minister has explained why Article 50 of the Consti...\n",
      "     Q (Tuan D.R Seenivasagam): Sir, if we amend up to sub-section (3) of Article 50-sub-section (4) does not deal with the problem ...\n",
      "     Q (YB Tan Sri Dato' Seri Haji Abdul Hadi bin Awang): Mr Speaker, Sir, I beg to second the motion. 988 Mr Speaker: The question is that the Malaysia Bill ...\n",
      "     Q (YB Dato' Sri Dr. Wee Jeck Seng): Dato' Yang di-Pertua, manakala sampai ka-abad yang akhir, timbul-lah pertentangan di-Benua Eropah de...\n",
      "\n",
      "Sample 4 | ID: 67334803d052c3fbabd834df | Date: 1975-07-09 | Decade: post1970 | Segments: 212\n",
      "   First speaker: Tuan V.Veerappen [None]\n",
      "   First text: Mohd. Salleh bin Abu Bakar. Penterjemah Melayu Kanan/Pemangku Penolong Setia BAHAGIAN PENYATA RASM Penyunting: Yahya Manap.\n",
      "   QA Example:\n",
      "     Q (Tuan V.Veerappen): N. Ramaswamy. Louis Yeoh Sim Ngoh. Abdul Rahman bin Haji Abu Samah. Rani bin Rahim. Suhor bin Husin....\n",
      "     Q (Tuan Ng Ann Teck): Tuan g di-Pertua, soalan tambahan. Adakah ubuhan kilang-kilang penapis minyak ini ih belum dapat dij...\n",
      "     Q (Tuan V.Veerappen): Tuan Yang di-Pertua, adalah soalan lain, akan tetapi saya boleh angkan, iaitu PETRONAS sekarang ang ...\n",
      "     Q (YB Dato' Sri Dr. Wee Jeck Seng): Soalan tambahan, Tuan Yang di-Pertua. Adakah Yang Amat Berhormat Perdana Menteri sedar apabila ada k...\n",
      "   Injection Example:\n",
      "     Injection in Tuan Khaw Kai's speech: mentions Tuan Luhat Wan\n",
      "     Injection in Tuan Khaw Kai's speech: mentions Tuan Luhat Wan\n",
      "\n",
      "Sample 5 | ID: 6734b888538e3ad97ae5e237 | Date: 2016-03-17 | Decade: post1970 | Segments: 712\n",
      "   First speaker: Tuan Ong Tin Kim [None]\n",
      "   First text: Assalamualaikum warahmatullahi wabarakatuh, salam sejahtera, salam 1Malaysia. Tuan Yang di-Pertua, kadar saman yang tinggi hanya berkesan kepada merek...\n",
      "   QA Example:\n",
      "     Q (YB Datuk Jonathan bin Yasin): Terima kasih, Tuan Yang di-Pertua. Terima kasih Yang Berhormat Timbalan Menteri di atas jawapan yang...\n",
      "     Q (YB Tuan Yuneswaran a/l Ramaraj): Yang saya nampak terlampau berminat sangat untuk tanya soalan ini, Yang Berhormat Pokok Sena. Ini di...\n",
      "     Q (Dr V. David): Terima kasih Tuan Yang di- Pertua, terima kasih Yang Berhormat Menteri. Tadi Yang Berhormat Menteri ...\n",
      "     Q (Dr V. David): Kalau hendak disiplin, tak perlu ambil duit. Cukup buat disiplinlah, itulah pendidikan. Ini apa hend...\n",
      "\n",
      "Sample 6 | ID: 673377f8d052c3fbabd83942 | Date: 1992-12-23 | Decade: post1970 | Segments: 459\n",
      "   First speaker: Tuan Tan Kee Gak [None]\n",
      "   First text: Haji Taijadin bin Saberan.\n",
      "   QA Example:\n",
      "     Q (Tuan V.Veerappen): Haji Suhor bin Husin. Mohd. Saleh bin Mohd. Yusop. Supiah binti Dewak. Ismail bin Haji Hassan. Hajah...\n",
      "     Q (YB Tuan Lim Lip Eng): Tuan Yang di- hendak me Pertua, soalan tambahan. Mengenai IKS ada databagi kalangan orang bumiputera...\n",
      "     Q (Kosong): Yang , panjang sangat soalan itu....\n",
      "     Q (Kosong): Tidak, tidak Adadua-tiga soalan sahaja, minta ya. Dan berapakah peratusan yang diperolehi daripada t...\n",
      "   Injection Example:\n",
      "     Injection in Tuan Ong Tin Kim's speech: mentions Tuan Lau Dak Kee\n",
      "     Injection in Tuan Ong Tin Kim's speech: mentions Tuan Lau Dak Kee\n",
      "\n",
      "Sample 7 | ID: 67334dfad052c3fbabd83584 | Date: 1977-11-30 | Decade: post1970 | Segments: 87\n",
      "   First speaker: Tuan Ong Tin Kim [None]\n",
      "   First text: Haji A. Hasmuni bin Haji Hussein.\n",
      "   QA Example:\n",
      "     Q (Tuan V.Veerappen): N. Ramaswamy Louis Yeoh Sim Ngoh Abdul Rahman bin Haji Abu Samah Suhor bin Husin Amran bin Ahmad Moh...\n",
      "        A (Tuan Ong Tin Kim): Tuan Yang di-Pertua, saya mohon izin bagi pihak Jabatan Perdana Menteri untuk menjawab soalan Ahli Y...\n",
      "     Q (Tuan Ong Tin Kim): Tuan Yang di-Pertua, saya mohon izin bagi pihak Jabatan Perdana Menteri untuk menjawab soalan Ahli Y...\n",
      "     Q (Tuan Luhat Wan): Tuan Yang di-Pertua, soalan tambahan. Adakah Yang Berhormat Menteri berkenaan sedar keadaan ini berl...\n",
      "\n",
      "Sample 8 | ID: 67334f97d052c3fbabd835b1 | Date: 1978-10-26 | Decade: post1970 | Segments: 113\n",
      "   First speaker: Dr. Patau Rubis [None]\n",
      "   First text: D. Timbalan Menteri Pelajaran, A.M.N., P.J.K., J.P. (Bentong). - Timbalan Menteri Pertahanan, DATOâ€™ MoKH Timbalan Menteri Kesihatan, - (Santubong). 99...\n",
      "   QA Example:\n",
      "     Q (Tuan Ng Ann Teck): Ahli-ahli Yang Berhormat, Duli Yang Maha Mulia Seri Paduka Baginda Yang di-Pertuan Agong telah berke...\n",
      "     Q (YB Tuan Chow Yu Hui): Memandangkan kadar buta huruf di Malaysia adalah tinggi Per maka bolehkah Yang Berhormat Timbalan an...\n",
      "     Q (YB Tuan Sim Tze Tzin): Tuan g di-Pertua, soalan tambahan. Timbalan teri menyatakan bahawa Kerajaan sedar ai murid-murid yan...\n",
      "        A (YB Tuan Yuneswaran a/l Ramaraj): Soalan tambahan g pertama itu, saya rasa Yang Berhormat balan Menteri perlu minta notis kerana ak ad...\n",
      "\n",
      "Sample 9 | ID: 67336ee6d052c3fbabd8388a | Date: 1990-06-14 | Decade: post1970 | Segments: 255\n",
      "   First speaker: Tuan V.Veerappen [None]\n",
      "   First text: Abdullah bin Abdul Wahab.\n",
      "   QA Example:\n",
      "     Q (Tuan V.Veerappen): Shamsiah binti Md. Yusop Pelapor Perbahasan Parlimen: Suhor bin Husin. Mohd. Saleh bin Mohd. Yusof. ...\n",
      "        A (Tuan Luhat Wan): Kepialu tela (a) kadar penyakit AIDS di negara atau perkhid kita sekarang; dan gagal menceg (b) bera...\n",
      "     Q (Tuan Luhat Wan): Kepialu tela (a) kadar penyakit AIDS di negara atau perkhid kita sekarang; dan gagal menceg (b) bera...\n",
      "     Q (YB Tuan Lim Lip Eng): Tuan Yang di- Yang kedua, Pertua, soalan tambahan. Suka saya ber- Airod, saya suka tanya kepada Yang...\n",
      "   Injection Example:\n",
      "     Injection in Tuan Mark Koding's speech: mentions Dr. Chen Man Hin\n",
      "\n",
      "Sample 10 | ID: 673352f2d052c3fbabd83609 | Date: 1979-12-10 | Decade: post1970 | Segments: 183\n",
      "   First speaker: Tuan V.Veerappen [None]\n",
      "   First text: Datuk Azizul Rahman bin Abdul Aziz.\n",
      "   QA Example:\n",
      "     Q (Tuan Ho See Beng): Sebelum saya mengemukakan Maksud P. anggaran ini, Tuan Pengerusi, terlebih dahulu Ketiga saya yang m...\n",
      "        A (YB Tuan Pang Hok Liong): Kalau begitu Yang Berhormat tidak membaca Aturan Urusan Tuan C Mesyuarat. Bukankah hari ini dan beso...\n",
      "     Q (YB Tuan Pang Hok Liong): Kalau begitu Yang Berhormat tidak membaca Aturan Urusan Tuan C Mesyuarat. Bukankah hari ini dan beso...\n",
      "     Q (YB Tuan Yuneswaran a/l Ramaraj): Dan saya Berhormat juga tidak suka diganggu bila saya berucap. yang dibua disediakan Tuan Pengerusi,...\n",
      "\n",
      "Check output above. \n"
     ]
    }
   ],
   "source": [
    "all_docs = list(hansard_col.find({}, {\"_id\": 1, \"full_text\": 1, \"content_text\": 1, \"hansardDate\": 1}))\n",
    "random.shuffle(all_docs)\n",
    "test_docs = all_docs[:10]\n",
    "\n",
    "print(\"=== TESTING 10 RANDOM SAMPLES ===\")\n",
    "for idx, doc in enumerate(test_docs):\n",
    "    text = doc.get(\"full_text\") or doc.get(\"content_text\") or \"\"\n",
    "    if not text:\n",
    "        continue\n",
    "    result = segment_document(doc[\"_id\"], text, doc[\"hansardDate\"].year)\n",
    "    print(f\"\\nSample {idx+1} | ID: {doc['_id']} | Date: {doc['hansardDate'].date()} | Decade: {result['decade']} | Segments: {result['segment_count']}\")\n",
    "    \n",
    "    if result['segments']:\n",
    "        print(f\"   First speaker: {result['segments'][0]['speaker']} [{result['segments'][0]['constituency'] or 'None'}]\")\n",
    "        print(f\"   First text: {result['segments'][0]['text'][:150]}{'...' if len(result['segments'][0]['text']) > 150 else ''}\")\n",
    "        \n",
    "        # QA & Injection detection example\n",
    "        qa_examples = []\n",
    "        injection_examples = []\n",
    "        for i, seg in enumerate(result['segments']):\n",
    "            text_lower = seg['text'].lower()\n",
    "            if \"?\" in seg['text'] or \"pertanyaan\" in text_lower or \"soalan\" in text_lower:\n",
    "                qa_examples.append(f\"Q ({seg['speaker']}): {seg['text'][:100]}...\")\n",
    "                if i+1 < len(result['segments']):\n",
    "                    next_text = result['segments'][i+1]['text'].lower()\n",
    "                    if \"jawab\" in next_text or \"menjawab\" in next_text:\n",
    "                        qa_examples.append(f\"   A ({result['segments'][i+1]['speaker']}): {result['segments'][i+1]['text'][:100]}...\")\n",
    "            # Injection: other speaker name appears in text\n",
    "            for other_seg in result['segments']:\n",
    "                if other_seg['speaker'] != seg['speaker'] and other_seg['speaker'] in seg['text']:\n",
    "                    injection_examples.append(f\"Injection in {seg['speaker']}'s speech: mentions {other_seg['speaker']}\")\n",
    "        \n",
    "        if qa_examples:\n",
    "            print(\"   QA Example:\")\n",
    "            for ex in qa_examples[:4]:\n",
    "                print(f\"     {ex}\")\n",
    "        if injection_examples:\n",
    "            print(\"   Injection Example:\")\n",
    "            for ex in injection_examples[:2]:\n",
    "                print(f\"     {ex}\")\n",
    "\n",
    "print(\"\\nCheck output above. \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8a56bd7",
   "metadata": {},
   "source": [
    "### Multi-threaded run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df50614",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== FULL MULTI-THREADED RUN - SAVING 500 DOCUMENTS WITH METADATA ===\n",
      "Inserted batch of 50 | Total: 50/500\n",
      "Inserted batch of 50 | Total: 100/500\n",
      "Inserted batch of 50 | Total: 150/500\n",
      "Inserted batch of 50 | Total: 200/500\n",
      "Inserted batch of 50 | Total: 250/500\n",
      "Inserted batch of 50 | Total: 300/500\n",
      "Inserted batch of 50 | Total: 350/500\n",
      "Inserted batch of 50 | Total: 400/500\n"
     ]
    }
   ],
   "source": [
    "print(\"=== FULL MULTI-THREADED RUN - SAVING 500 DOCUMENTS WITH METADATA ===\")\n",
    "\n",
    "def process_single_doc(doc):\n",
    "    text = doc.get(\"full_text\") or doc.get(\"content_text\") or \"\"\n",
    "    if not text:\n",
    "        return None\n",
    "    year = doc[\"hansardDate\"].year\n",
    "    \n",
    "    # Run segmentation\n",
    "    segmented_result = segment_document(doc[\"_id\"], text, year)\n",
    "    \n",
    "    # Combine original metadata + segmentation output\n",
    "    saved_doc = {\n",
    "        \"original_id\": str(doc[\"_id\"]),\n",
    "        \"hansardDate\": doc.get(\"hansardDate\"),\n",
    "        \"full_text\": text,  # Keep raw text for reference\n",
    "        \"split_type\": doc.get(\"split_type\"),\n",
    "        \"mesyuarat\": doc.get(\"mesyuarat\"),\n",
    "        \"parlimen\": doc.get(\"parlimen\"),\n",
    "        \"parlimen_range\": doc.get(\"parlimen_range\"),\n",
    "        \"penggal\": doc.get(\"penggal\"),\n",
    "        \"decade\": segmented_result[\"decade\"],\n",
    "        \"segment_count\": segmented_result[\"segment_count\"],\n",
    "        \"segmentation_output\": segmented_result[\"segments\"]  # Main result\n",
    "    }\n",
    "    return saved_doc\n",
    "\n",
    "all_documents = list(hansard_col.find({}, {\n",
    "    \"_id\": 1,\n",
    "    \"full_text\": 1,\n",
    "    \"content_text\": 1,\n",
    "    \"hansardDate\": 1,\n",
    "    \"split_type\": 1,\n",
    "    \"mesyuarat\": 1,\n",
    "    \"parlimen\": 1,\n",
    "    \"parlimen_range\": 1,\n",
    "    \"penggal\": 1\n",
    "}))\n",
    "\n",
    "MAX_WORKERS = 20\n",
    "batch_size = 50\n",
    "inserted_count = 0\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
    "    futures = [executor.submit(process_single_doc, doc) for doc in all_documents]\n",
    "    batch = []\n",
    "    \n",
    "    for future in as_completed(futures):\n",
    "        result = future.result()\n",
    "        if result:\n",
    "            batch.append(result)\n",
    "            inserted_count += 1\n",
    "        \n",
    "        if len(batch) >= batch_size:\n",
    "            local_db = get_db_connection()\n",
    "            local_db[\"hansard_segmented500\"].insert_many(batch)\n",
    "            print(f\"Inserted batch of {len(batch)} | Total: {inserted_count}/{len(all_documents)}\")\n",
    "            batch = []\n",
    "    \n",
    "    if batch:\n",
    "        local_db = get_db_connection()\n",
    "        local_db[\"hansard_segmented500\"].insert_many(batch)\n",
    "        print(f\"Final batch inserted: {len(batch)}\")\n",
    "\n",
    "print(f\"\\nSegmentation completed! {inserted_count} documents with full metadata saved to 'hansard_segmented500'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd42561",
   "metadata": {},
   "source": [
    "### Continue run after interruption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e070b3be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== FULL MULTI-THREADED RUN - SAVING 500 DOCUMENTS WITH METADATA ===\n",
      "Already processed: 450 documents | Total: 500 | Remaining: 50\n",
      "This run will process 50 new documents\n",
      "\n",
      "Inserted batch of 50 | This run: 50/50 | Total processed: 500/500\n",
      "\n",
      "This run completed! Inserted 50 new documents.\n",
      "Overall: 500 / 500 documents saved to 'hansard_segmented500'\n"
     ]
    }
   ],
   "source": [
    "from bson import ObjectId  \n",
    "\n",
    "print(\"=== FULL MULTI-THREADED RUN - SAVING 500 DOCUMENTS WITH METADATA ===\")\n",
    "db = get_db_connection()  # Get DB connection early to check progress\n",
    "\n",
    "# Count already processed and total documents\n",
    "already_processed = db[\"hansard_segmented500\"].count_documents({})\n",
    "total_docs = hansard_col.count_documents({})\n",
    "print(f\"Already processed: {already_processed} documents | Total: {total_docs} | Remaining: {total_docs - already_processed}\")\n",
    "\n",
    "# Get list of original_id values that have already been processed\n",
    "processed_ids = db[\"hansard_segmented500\"].distinct(\"original_id\")\n",
    "\n",
    "# Build query to fetch only unprocessed documents\n",
    "if processed_ids:\n",
    "    query_filter = {\"_id\": {\"$nin\": [ObjectId(pid) for pid in processed_ids]}}\n",
    "else:\n",
    "    query_filter = {}  # First run: process everything\n",
    "\n",
    "all_documents = list(hansard_col.find(query_filter, {\n",
    "    \"_id\": 1,\n",
    "    \"full_text\": 1,\n",
    "    \"content_text\": 1,\n",
    "    \"hansardDate\": 1,\n",
    "    \"split_type\": 1,\n",
    "    \"mesyuarat\": 1,\n",
    "    \"parlimen\": 1,\n",
    "    \"parlimen_range\": 1,\n",
    "    \"penggal\": 1\n",
    "}))\n",
    "\n",
    "if not all_documents:\n",
    "    print(\"All documents have already been processed! Nothing to do.\")\n",
    "    exit()\n",
    "\n",
    "print(f\"This run will process {len(all_documents)} new documents\\n\")\n",
    "\n",
    "# === Proceed segmentation and saving ===\n",
    "\n",
    "def process_single_doc(doc):\n",
    "    text = doc.get(\"full_text\") or doc.get(\"content_text\") or \"\"\n",
    "    if not text:\n",
    "        return None\n",
    "    year = doc[\"hansardDate\"].year\n",
    "    \n",
    "    # Run segmentation\n",
    "    segmented_result = segment_document(doc[\"_id\"], text, year)\n",
    "    \n",
    "    # Combine original metadata + segmentation output\n",
    "    saved_doc = {\n",
    "        \"original_id\": str(doc[\"_id\"]),\n",
    "        \"hansardDate\": doc.get(\"hansardDate\"),\n",
    "        \"full_text\": text,  # Keep raw text for reference\n",
    "        \"split_type\": doc.get(\"split_type\"),\n",
    "        \"mesyuarat\": doc.get(\"mesyuarat\"),\n",
    "        \"parlimen\": doc.get(\"parlimen\"),\n",
    "        \"parlimen_range\": doc.get(\"parlimen_range\"),\n",
    "        \"penggal\": doc.get(\"penggal\"),\n",
    "        \"decade\": segmented_result[\"decade\"],\n",
    "        \"segment_count\": segmented_result[\"segment_count\"],\n",
    "        \"segmentation_output\": segmented_result[\"segments\"]  # Main result\n",
    "    }\n",
    "    return saved_doc\n",
    "\n",
    "MAX_WORKERS = 20\n",
    "batch_size = 50\n",
    "inserted_count = 0  # Count of documents inserted in this run\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
    "    futures = [executor.submit(process_single_doc, doc) for doc in all_documents]\n",
    "    batch = []\n",
    "    \n",
    "    for future in as_completed(futures):\n",
    "        result = future.result()\n",
    "        if result:\n",
    "            batch.append(result)\n",
    "            inserted_count += 1\n",
    "        \n",
    "        if len(batch) >= batch_size:\n",
    "            local_db = get_db_connection()\n",
    "            local_db[\"hansard_segmented500\"].insert_many(batch)\n",
    "            print(f\"Inserted batch of {len(batch)} | This run: {inserted_count}/{len(all_documents)} | \"\n",
    "                  f\"Total processed: {already_processed + inserted_count}/{total_docs}\")\n",
    "            batch = []\n",
    "    \n",
    "    # Insert any remaining documents in the final batch\n",
    "    if batch:\n",
    "        local_db = get_db_connection()\n",
    "        local_db[\"hansard_segmented500\"].insert_many(batch)\n",
    "        print(f\"Final batch inserted: {len(batch)}\")\n",
    "\n",
    "print(f\"\\nThis run completed! Inserted {inserted_count} new documents.\")\n",
    "print(f\"Overall: {already_processed + inserted_count} / {total_docs} documents saved to 'hansard_segmented500'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MyParliament-nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
