{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f26b7772",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8ad2856b",
   "metadata": {},
   "source": [
    "### Imports and MongoDB Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "91262db9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 350 raw documents for Pipeline 2 (TF-IDF + LDA)\n"
     ]
    }
   ],
   "source": [
    "import pymongo\n",
    "import os\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import nltk\n",
    "from nltk.corpus import stopwords as nltk_stopwords\n",
    "from gensim.models import LdaModel\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "from sklearn.metrics import silhouette_score\n",
    "import networkx as nx\n",
    "from pyvis.network import Network\n",
    "import json\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Load environment\n",
    "project_root = Path.cwd().parents[0] if 'parents' in dir(Path.cwd()) else Path.cwd()\n",
    "backend_env_path = project_root / \"3_app_system\" / \"backend\" / \".env\"\n",
    "load_dotenv(backend_env_path)\n",
    "\n",
    "client = pymongo.MongoClient(os.getenv(\"MONGO_URI\"))\n",
    "db = client[\"MyParliament\"]\n",
    "\n",
    "# Load same raw text as Pipeline 1 (fair comparison)\n",
    "raw_col = db[\"hansard_core500\"]\n",
    "docs = list(raw_col.find({\"split_type\": \"train\"}, {\"full_text\": 1}))\n",
    "texts = [doc[\"full_text\"] for doc in docs if doc.get(\"full_text\") and doc[\"full_text\"].strip()]\n",
    "print(f\"Loaded {len(texts)} raw documents for Pipeline 2 (TF-IDF + LDA)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb1985fd",
   "metadata": {},
   "source": [
    "### Bilingual TF-IDF Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dbb73345",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using same bilingual stopwords: 673 total\n",
      "TF-IDF matrix shape: (350, 226228)\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords', quiet=True)\n",
    "\n",
    "malay_stopwords_path = \"stopwords-ms-MannualOp.txt\"  \n",
    "with open(malay_stopwords_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    malay_stopwords = [line.strip() for line in f if line.strip()]\n",
    "\n",
    "english_stopwords = list(nltk_stopwords.words('english'))\n",
    "combined_stopwords = english_stopwords + malay_stopwords\n",
    "print(f\"Using same bilingual stopwords: {len(combined_stopwords)} total\")\n",
    "\n",
    "vectorizer = TfidfVectorizer(\n",
    "    max_df=0.7,\n",
    "    min_df=5,\n",
    "    stop_words=combined_stopwords,\n",
    "    ngram_range=(1, 3),\n",
    "    sublinear_tf=True,\n",
    "    lowercase=True\n",
    ")\n",
    "\n",
    "tfidf_matrix = vectorizer.fit_transform(texts)\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "print(f\"TF-IDF matrix shape: {tfidf_matrix.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62e1321d",
   "metadata": {},
   "source": [
    "### Tokenization + LDA Topic Number Tuning (10-50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning LDA topic number (10-50)...\n",
      "Topics=10: Perplexity=-8.10, C_V=0.4296\n",
      "Topics=15: Perplexity=-8.20, C_V=0.4322\n",
      "Topics=20: Perplexity=-8.31, C_V=0.4312\n",
      "Topics=25: Perplexity=-8.43, C_V=0.4292\n",
      "Topics=30: Perplexity=-8.55, C_V=0.4240\n",
      "Topics=35: Perplexity=-8.67, C_V=0.4256\n",
      "Topics=40: Perplexity=-8.80, C_V=0.4285\n",
      "Topics=45: Perplexity=-8.91, C_V=0.4232\n",
      "Topics=50: Perplexity=-9.07, C_V=0.4185\n",
      "\n",
      "Best LDA model: 15 topics (C_V=0.4322, Perplexity=-8.20)\n",
      "Best LDA model saved to results/best_lda_model.pkl\n"
     ]
    }
   ],
   "source": [
    "tokenized_texts = [text.lower().split() for text in texts]\n",
    "dictionary = Dictionary(tokenized_texts)\n",
    "corpus = [dictionary.doc2bow(text) for text in tokenized_texts]\n",
    "\n",
    "best_coherence = -np.inf\n",
    "best_perplexity = np.inf\n",
    "best_model = None\n",
    "best_num_topics = 0\n",
    "\n",
    "print(\"Tuning LDA topic number (10-50)...\")\n",
    "for num_topics in range(10, 51, 5):\n",
    "    lda_model = LdaModel(\n",
    "        corpus=corpus,\n",
    "        id2word=dictionary,\n",
    "        num_topics=num_topics,\n",
    "        random_state=42,\n",
    "        passes=10,\n",
    "        iterations=100,\n",
    "        eval_every=1\n",
    "    )\n",
    "    \n",
    "    perplexity = lda_model.log_perplexity(corpus)\n",
    "    \n",
    "    topics = [[dictionary[id] for id, prob in lda_model.get_topic_terms(topic_id, topn=10)] \n",
    "              for topic_id in range(num_topics)]\n",
    "    coherence_model = CoherenceModel(topics=topics, texts=tokenized_texts, dictionary=dictionary, coherence='c_v')\n",
    "    coherence = coherence_model.get_coherence()\n",
    "    \n",
    "    print(f\"Topics={num_topics}: Perplexity={perplexity:.2f}, C_V={coherence:.4f}\")\n",
    "    \n",
    "    if coherence > best_coherence:\n",
    "        best_coherence = coherence\n",
    "        best_perplexity = perplexity\n",
    "        best_model = lda_model \n",
    "        best_num_topics = num_topics\n",
    "\n",
    "print(f\"\\nBest LDA model: {best_num_topics} topics (C_V={best_coherence:.4f}, Perplexity={best_perplexity:.2f})\")\n",
    "\n",
    "with open(\"model/best_lda_model.pkl\", \"wb\") as f:\n",
    "    pickle.dump(best_model, f)\n",
    "print(\"Best LDA model saved to model/best_lda_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe4757b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline 2 - Silhouette Score: 0.8402\n"
     ]
    }
   ],
   "source": [
    "# Matrix construction\n",
    "doc_topic_matrix = np.zeros((len(corpus), best_num_topics))\n",
    "for i, bow in enumerate(corpus):\n",
    "    if bow:\n",
    "        dist = best_model.get_document_topics(bow, minimum_probability=0.0)\n",
    "        for topic_id, prob in dist:\n",
    "            if topic_id < best_num_topics:\n",
    "                doc_topic_matrix[i, topic_id] = prob\n",
    "\n",
    "# Normalize\n",
    "doc_topic_matrix = np.nan_to_num(doc_topic_matrix)\n",
    "row_sums = doc_topic_matrix.sum(axis=1, keepdims=True)\n",
    "doc_topic_matrix = np.divide(doc_topic_matrix, row_sums, out=np.zeros_like(doc_topic_matrix), where=row_sums!=0)\n",
    "\n",
    "labels = np.argmax(doc_topic_matrix, axis=1)\n",
    "silhouette = silhouette_score(doc_topic_matrix, labels, sample_size=15000, random_state=42)\n",
    "print(f\"Pipeline 2 - Silhouette Score: {silhouette:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba6b734",
   "metadata": {},
   "source": [
    "### Extract Top Words + Compute Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline 2 - C_V Coherence: 0.4322\n",
      "Pipeline 2 - NPMI Coherence: -0.0236\n",
      "Pipeline 2 - Topic Diversity: 0.1600 (based on 15 topics)\n",
      "Pipeline 2 - Perplexity: -8.1974\n"
     ]
    }
   ],
   "source": [
    "top_words_per_topic = []\n",
    "for topic_id in range(best_num_topics):\n",
    "    words_probs = best_model.get_topic_terms(topic_id, topn=10)\n",
    "    words = [dictionary[id] for id, prob in words_probs]\n",
    "    top_words_per_topic.append(words)\n",
    "\n",
    "# Filter empty\n",
    "valid_top_words = [words for words in top_words_per_topic if words]\n",
    "valid_n_topics = len(valid_top_words)\n",
    "\n",
    "# Coherence \n",
    "coherence_cv = best_coherence\n",
    "coherence_npmi = CoherenceModel(topics=valid_top_words, texts=tokenized_texts, dictionary=dictionary, coherence='c_npmi').get_coherence()\n",
    "\n",
    "# Topic Diversity\n",
    "all_top_words_set = set(word for cluster in valid_top_words for word in cluster[:10])\n",
    "td = len(all_top_words_set) / (valid_n_topics * 10) if valid_n_topics > 0 else 0\n",
    "\n",
    "print(f\"Pipeline 2 - C_V Coherence: {coherence_cv:.4f}\")\n",
    "print(f\"Pipeline 2 - NPMI Coherence: {coherence_npmi:.4f}\")\n",
    "print(f\"Pipeline 2 - Topic Diversity: {td:.4f} (based on {valid_n_topics} topics)\")\n",
    "print(f\"Pipeline 2 - Perplexity: {best_perplexity:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de191a8e",
   "metadata": {},
   "source": [
    "### Network Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "484e7d80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/data/MyParliament/2_ml_modeling/network_graph/pipeline2_network.html\n",
      "Network graph saved: {html_path}\n"
     ]
    }
   ],
   "source": [
    "def generate_network_graph(top_words_per_topic, num_topics):\n",
    "    network_graph_dir = project_root / \"2_ml_modeling/network_graph\"\n",
    "    network_graph_dir.mkdir(parents=True, exist_ok=True)\n",
    "    html_path = network_graph_dir / \"pipeline2_network.html\"\n",
    "\n",
    "    G = nx.Graph()\n",
    "    for topic_id, words in enumerate(top_words_per_topic):\n",
    "        if not words:\n",
    "            continue\n",
    "        topic_node = f\"Topic_{topic_id}\"\n",
    "        G.add_node(topic_node, size=80, group=topic_id, title=f\"Topic {topic_id}\", shape='ellipse', color='red')\n",
    "        for word in words:\n",
    "            G.add_node(word, size=30, group=topic_id, color='lightblue')\n",
    "            G.add_edge(topic_node, word, weight=5)\n",
    "        for i in range(len(words)):\n",
    "            for j in range(i+1, len(words)):\n",
    "                G.add_edge(words[i], words[j], weight=2)\n",
    "    \n",
    "    net = Network(height=\"900px\", width=\"100%\", notebook=True, cdn_resources='in_line')\n",
    "    net.from_nx(G)\n",
    "    net.show_buttons(filter_=['physics'])\n",
    "    net.force_atlas_2based()\n",
    "    net.show(str(html_path))\n",
    "    print(\"Network graph saved: {html_path}\")\n",
    "\n",
    "generate_network_graph(top_words_per_topic, best_num_topics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db05a3a",
   "metadata": {},
   "source": [
    "### Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f7cf75f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline 2 COMPLETED! Results saved.\n"
     ]
    }
   ],
   "source": [
    "results = {\n",
    "    \"pipeline\": \"02_tfidf_lda\",\n",
    "    \"best_num_topics\": best_num_topics,\n",
    "    \"silhouette\": float(silhouette),\n",
    "    \"coherence_cv\": float(coherence_cv),\n",
    "    \"coherence_npmi\": float(coherence_npmi),\n",
    "    \"topic_diversity\": float(td),\n",
    "    \"perplexity\": float(best_perplexity),\n",
    "    \"valid_topics\": valid_n_topics\n",
    "}\n",
    "\n",
    "with open(\"results/pipeline2_results.json\", \"w\") as f:\n",
    "    json.dump(results, f, indent=2)\n",
    "\n",
    "print(\"Pipeline 2 COMPLETED! Results saved.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
